"""
Google Image Retrieval with GroundingDINO verification.

Downloads images from Google Image Search for specified object categories,
verifies them using GroundingDINO object detection, and saves validated images
with bounding box annotations.

Supports two query modes:
- Classic: Simple "A photo of a {category}" queries
- LLM: Diverse queries generated by Gemini for better image variety

Based on: https://github.com/cvlab-columbia/DoubleRight/blob/master/google_image_search_url.py
"""

import argparse
import json
import logging
import os
from dataclasses import dataclass
from typing import Optional

import torch
from dotenv import load_dotenv
from google_images_search import GoogleImagesSearch
from PIL import Image

from groundingdino.util.inference import load_model, load_image, predict

# Download required NLTK data
import nltk
nltk.download('punkt', quiet=True)
nltk.download('averaged_perceptron_tagger', quiet=True)

# =============================================================================
# Configuration
# =============================================================================

load_dotenv()

# Logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class Config:
    """Configuration constants for the retrieval pipeline."""
    # Google API
    google_api_key: str = os.getenv('GOOGLE_API_KEY', '')
    google_cx: str = os.getenv('GOOGLE_CX', '')
    gemini_api_key: str = os.getenv('GEMINI_API_KEY', '')
    
    # Device
    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    
    # Detection thresholds
    score_threshold: float = 0.5
    box_threshold: float = 0.35
    text_threshold: float = 0.25
    
    # Search limits
    search_limit: int = 60  # Max images to search per category
    
    # Output paths
    images_subdir: str = 'imgs/'
    annotations_file: str = 'annotations.json'
    
    # Query template
    query_template: str = "A photo of a "


CONFIG = Config()


def get_default_model_paths() -> tuple[str, str]:
    """Get default GroundingDINO model config and weights paths."""
    import groundingdino
    gd_path = os.path.dirname(groundingdino.__file__)
    config_path = os.path.join(gd_path, "config", "GroundingDINO_SwinB_cfg.py")
    weights_id = "IDEA-Research/grounding-dino-base"
    return config_path, weights_id


# =============================================================================
# Model Functions
# =============================================================================

def load_grounding_dino(config_path: str, weights_path: str) -> object:
    """
    Load GroundingDINO model, downloading weights from HuggingFace if needed.
    
    Args:
        config_path: Path to the model config file
        weights_path: Path to weights file or HuggingFace repo ID
        
    Returns:
        Loaded GroundingDINO model
    """
    from huggingface_hub import hf_hub_download
    
    # Download weights if not a local file
    if not os.path.exists(weights_path):
        logger.info("Downloading GroundingDINO weights from HuggingFace...")
        weights_path = hf_hub_download(
            repo_id='ShilongLiu/GroundingDINO',
            filename='groundingdino_swinb_cogcoor.pth'
        )
        logger.info(f"Weights downloaded to: {weights_path}")
    
    logger.info(f"Loading GroundingDINO model from {weights_path}")
    model = load_model(config_path, weights_path, device=CONFIG.device)
    logger.info(f"Model loaded on {CONFIG.device}")
    return model


def detect_objects(
    model, 
    image_path: str, 
    text_prompt: str,
    box_threshold: float,
    text_threshold: float
) -> tuple[list, list, list]:
    """
    Run GroundingDINO inference on a single image.
    
    Args:
        model: Loaded GroundingDINO model
        image_path: Path to the image file
        text_prompt: Text description of object to detect
        box_threshold: Confidence threshold for box detection
        text_threshold: Confidence threshold for text matching
        
    Returns:
        Tuple of (boxes_xyxy, scores, phrases)
    """
    image_source, image_tensor = load_image(image_path)
    
    boxes, logits, phrases = predict(
        model=model,
        image=image_tensor,
        caption=text_prompt,
        box_threshold=box_threshold,
        text_threshold=text_threshold,
        device=CONFIG.device
    )
    
    # Convert from normalized cxcywh to pixel xyxy
    h, w = image_source.shape[:2]
    boxes_xyxy = []
    for box in boxes:
        cx, cy, bw, bh = box.tolist()
        x1, y1 = (cx - bw/2) * w, (cy - bh/2) * h
        x2, y2 = (cx + bw/2) * w, (cy + bh/2) * h
        boxes_xyxy.append([x1, y1, x2, y2])
    
    return boxes_xyxy, logits.tolist(), phrases


# =============================================================================
# Category Loading
# =============================================================================

def load_categories(cats_path: str, gt_path: str) -> tuple[list, dict]:
    """
    Load categories from JSON file or COCO annotations.
    
    Args:
        cats_path: Path to categories JSON file
        gt_path: Path to ground truth COCO annotations (fallback)
        
    Returns:
        Tuple of (category_list, category_mapper)
    """
    if os.path.exists(cats_path):
        with open(cats_path) as f:
            data = json.load(f)
            
        if 'category_list_real' in data:
            real_cats = data['category_list_real']
            find_cats = data['category_list_find']
        else:
            real_cats = data['categories']
            find_cats = data['categories']
    else:
        from pycocotools.coco import COCO
        coco = COCO(gt_path)
        categories = coco.loadCats(coco.getCatIds())
        real_cats = [cat["name"] for cat in categories]
        find_cats = real_cats.copy()
    
    mapper = dict(zip(find_cats, real_cats))
    logger.info(f"Loaded {len(find_cats)} categories")
    return find_cats, mapper


# =============================================================================
# LLM Query Generator  
# =============================================================================

def create_llm_processor() -> Optional[object]:
    """
    Initialize the LLM query processor if API key is available.
    
    Returns:
        GoogleProcessor instance or None
    """
    if not CONFIG.gemini_api_key:
        logger.warning("GEMINI_API_KEY not found - LLM queries unavailable")
        return None
    
    try:
        import sys
        sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from raxo2.processors.google import GoogleProcessor
        
        processor = GoogleProcessor(
            CONFIG.google_api_key, 
            CONFIG.google_cx, 
            CONFIG.gemini_api_key
        )
        logger.info("LLM query processor initialized (Gemini)")
        return processor
    except ImportError as e:
        logger.warning(f"Could not import GoogleProcessor: {e}")
        return None


def generate_queries(category: str, llm_processor: Optional[object]) -> list[str]:
    """
    Generate search queries for a category.
    
    Args:
        category: Object category name
        llm_processor: Optional LLM processor for diverse queries
        
    Returns:
        List of search queries
    """
    if llm_processor:
        try:
            queries = llm_processor.generate_queries(category)
            logger.info(f"LLM generated {len(queries)} queries for '{category}'")
            return queries
        except Exception as e:
            logger.warning(f"LLM query generation failed: {e}, using classic query")
    
    query = f"{CONFIG.query_template}{category}"
    logger.info(f"Searching for: {query}")
    return [query]


# =============================================================================
# Image Search & Download
# =============================================================================

def search_images(queries: list[str], limit: int) -> list:
    """
    Search Google Images with the given queries.
    
    Args:
        queries: List of search queries
        limit: Maximum total images to retrieve
        
    Returns:
        List of image results
    """
    all_images = []
    images_per_query = max(1, limit // len(queries))
    
    for query in queries:
        search_params = {
            'q': query,
            'num': min(images_per_query, limit),
            'searchType': 'image',
            'dateRestrict': 'y7',
            'safe': '',
            'fileType': 'jpg|png',
            'imgType': 'photo',
            'lr': 'lang_en',
        }
        
        try:
            gis = GoogleImagesSearch(CONFIG.google_api_key, CONFIG.google_cx)
            gis.search(search_params=search_params)
            all_images.extend(gis.results())
        except Exception as e:
            logger.error(f"Search error for '{query}': {e}")
            continue
    
    return all_images


def download_and_rename(image, output_dir: str, category: str, img_id: int) -> Optional[str]:
    """
    Download an image and rename it with category prefix.
    
    Returns:
        New image path or None if download failed
    """
    try:
        path = os.path.join(output_dir, CONFIG.images_subdir)
        os.makedirs(path, exist_ok=True)
        image.download(path)
        
        original_name = os.path.basename(image.path)
        _, ext = os.path.splitext(original_name)
        new_name = f"cat_{category}_{img_id}{ext}"
        new_path = os.path.join(path, new_name)
        
        os.rename(image.path, new_path)
        return new_path
    except Exception as e:
        logger.warning(f"Download failed: {e}")
        return None


# =============================================================================
# Main Pipeline
# =============================================================================

def process_category(
    category: str,
    super_category: str,
    model,
    images: list,
    output_dir: str,
    n_images: int,
    box_threshold: float,
    text_threshold: float,
    start_img_id: int
) -> tuple[list[dict], int]:
    """
    Process images for a single category.
    
    Returns:
        Tuple of (annotations_list, next_img_id)
    """
    annotations = []
    img_id = start_img_id
    valid_count = 0
    
    for image in images:
        if valid_count >= n_images:
            break
            
        # Download and rename
        image_path = download_and_rename(image, output_dir, super_category, img_id)
        if not image_path:
            continue
        img_id += 1
        
        # Run detection
        try:
            boxes, scores, _ = detect_objects(
                model, image_path, category, box_threshold, text_threshold
            )
        except Exception as e:
            logger.warning(f"Detection error for {image_path}: {e}")
            continue
        
        if not boxes or not scores:
            continue
        
        # Get best detection
        best_idx = scores.index(max(scores))
        best_score = scores[best_idx]
        best_box = boxes[best_idx]
        
        if best_score <= CONFIG.score_threshold:
            continue
        
        # Validate image can be opened
        try:
            Image.open(image_path)
        except Exception:
            continue
        
        # Save annotation
        annotations.append({
            "image_name": os.path.basename(image_path),
            "url": image.url,
            "category": category,
            "super_category": super_category,
            "bbox_xyxy": best_box,
            "score": best_score
        })
        valid_count += 1
    
    logger.info(f"Category '{category}' ({super_category}): {valid_count} valid images")
    return annotations, img_id


def main(args):
    """Main entry point for the image retrieval pipeline."""
    # Load model
    model = load_grounding_dino(args.model_config, args.model_weights)
    os.makedirs(args.out, exist_ok=True)
    
    # Load categories
    categories, mapper = load_categories(args.cats, args.cats_from_gt)
    
    # Initialize LLM processor if requested
    llm_processor = create_llm_processor() if args.use_llm_queries else None
    
    # Process each category
    all_annotations = []
    img_id = 0
    
    for category in categories:
        super_category = mapper[category]
        
        # Generate and execute search queries
        queries = generate_queries(category, llm_processor)
        images = search_images(queries, CONFIG.search_limit)
        
        # Process images
        annotations, img_id = process_category(
            category=category,
            super_category=super_category,
            model=model,
            images=images,
            output_dir=args.out,
            n_images=int(args.n),
            box_threshold=args.box_threshold,
            text_threshold=args.text_threshold,
            start_img_id=img_id
        )
        all_annotations.extend(annotations)
    
    # Save annotations
    output_path = os.path.join(args.out, CONFIG.annotations_file)
    with open(output_path, 'w') as f:
        json.dump({"images": all_annotations}, f, indent=2)
    logger.info(f"Saved {len(all_annotations)} annotations to {output_path}")


# =============================================================================
# CLI
# =============================================================================

def parse_args():
    """Parse command line arguments."""
    default_config, default_weights = get_default_model_paths()
    
    parser = argparse.ArgumentParser(
        description='Download and verify images from Google Image Search using GroundingDINO'
    )
    parser.add_argument('--cats', required=True, 
                        help='Path to categories JSON file')
    parser.add_argument('--n', required=True, type=int,
                        help='Number of images per category')
    parser.add_argument('--out', required=True, 
                        help='Output directory')
    parser.add_argument('--cats_from_gt', required=True, 
                        help='Path to COCO annotations (fallback for categories)')
    parser.add_argument('--model_config', default=default_config,
                        help='GroundingDINO config path')
    parser.add_argument('--model_weights', default=default_weights,
                        help='GroundingDINO weights path or HuggingFace repo')
    parser.add_argument('--box_threshold', type=float, default=CONFIG.box_threshold,
                        help='Box detection threshold')
    parser.add_argument('--text_threshold', type=float, default=CONFIG.text_threshold,
                        help='Text matching threshold')
    parser.add_argument('--use_llm_queries', action='store_true',
                        help='Use Gemini LLM to generate diverse search queries')
    
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    main(args)
